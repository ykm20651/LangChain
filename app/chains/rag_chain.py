"""
RAGChain - Retrieval-Augmented Generation (ê²€ìƒ‰ ê¸°ë°˜ ìƒì„± ì²´ì¸)
ë³´í—˜ì‚¬ ë‚´ë¶€ ë¬¸ì²´(ê³µë¬¸ì²´)ë¡œ ê°•í™”ëœ ë²„ì „
"""

from typing import List, Optional
from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
from langchain.schema import Document
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough
from app.services.vectorstore import VectorStoreService


class RAGChain:
    def __init__(
        self,
        collection: str = "default",
        top_k: int = 4,
        model: str = "gpt-4o-mini",
        temperature: float = 0.2,
        max_context_len: int = 3000,
        include_sources: bool = True,
        debug: bool = False,
    ):
        """
        RAG ì²´ì¸ ì´ˆê¸°í™”
        """
        self.collection = collection
        self.top_k = top_k
        self.include_sources = include_sources
        self.debug = debug
        self.max_context_len = max_context_len

        # (1) ë²¡í„°ìŠ¤í† ì–´ ì„œë¹„ìŠ¤
        self.vs = VectorStoreService()
        self.retriever = self.vs.get_retriever(collection=collection, k=top_k)

        # (2) LLM
        self.llm = ChatOpenAI(model=model, temperature=temperature)

        # (3) ì¶œë ¥ íŒŒì„œ
        self.parser = StrOutputParser()

        # (4) í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ (ë³´í—˜ì‹¬ì‚¬ ë¬¸ì²´)
        self.prompt = ChatPromptTemplate.from_template(
            """
ë‹¹ì‹ ì€ í•´ìƒë³´í—˜ ì‹¬ì‚¬ê´€ì´ë©°, ì•„ë˜ [ê²€ìƒ‰ ë¬¸ë§¥]ì€ ê´€ë ¨ ë²•ë ¹Â·ì•½ê´€Â·í˜‘ì•½ì—ì„œ ì¶”ì¶œí•œ ë‚´ìš©ì´ë‹¤.
ì´ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ê³  ë³´ê³ ì„œ ë° ë³´í—˜ê¸ˆ ì²­êµ¬ì„œ ì‘ì„±ì— í•„ìš”í•œ "ë²•ì  ê·¼ê±° ë¬¸ë‹¨"ì„ ì‘ì„±í•˜ë¼.

ì‘ì„± ê·œì¹™:
1. ë¬¸ì²´ëŠ” ê³µì‹ ë³´ê³ ì„œì²´(ì˜ˆ: "~ì— ì˜ê±°í•˜ì—¬", "~ìœ¼ë¡œ íŒë‹¨ëœë‹¤")ë¡œ í†µì¼í•œë‹¤.
2. ì‚¬ì‹¤ í™•ì¸ì´ ë¶ˆê°€ëŠ¥í•œ ë‚´ìš©ì€ "í™•ì¸ ë¶ˆê°€"ë¡œ ëª…ì‹œí•œë‹¤.
3. ë²•ë ¹, í˜‘ì•½, ì•½ê´€ ëª…ì¹­ì€ ì •í™•íˆ í‘œê¸°í•˜ê³ , ì¡°í•­ì´ ìˆë‹¤ë©´ ë²ˆí˜¸ë¥¼ í•¨ê»˜ ì ëŠ”ë‹¤.
4. ê°ê´€ì  ì‚¬ì‹¤Â·ì¡°ë¬¸ ì¤‘ì‹¬ìœ¼ë¡œ ê¸°ìˆ í•˜ê³ , ì£¼ê´€ì  íŒë‹¨Â·ê¶Œìœ  í‘œí˜„ì€ í”¼í•œë‹¤.
5. ì›ë¬¸ ë¬¸ë§¥ ì¤‘ ì¤‘ìš” ë¬¸êµ¬ëŠ” â€˜â€œ...â€â€™ë¡œ ì¸ìš© í‘œì‹œí•œë‹¤.
6. ê²°ë¡  ë¬¸ì¥ì€ í•­ìƒ â€œë”°ë¼ì„œ ë³¸ ì‚¬ê³ ëŠ” ìœ„ ì¡°í•­ì— ì˜ê±°í•˜ì—¬ ...ë¡œ ë¶„ë¥˜ëœë‹¤.â€ í˜•ì‹ìœ¼ë¡œ ë§ˆë¬´ë¦¬í•œë‹¤.

[ê²€ìƒ‰ ë¬¸ë§¥]
{context}

[ì§ˆë¬¸/ìš”ì²­ ì‚¬í•­]
{question}
"""
        )

        # (5) ì²´ì¸ êµ¬ì„±
        self.chain = (
            {"context": self._context_from_retriever, "question": RunnablePassthrough()}
            | self.prompt
            | self.llm
            | self.parser
        )

    # -----------------------------
    # ë‚´ë¶€ ë©”ì„œë“œ
    # -----------------------------
    def _context_from_retriever(self, question: str) -> str:
        """
        Retrieverë¡œ ë¬¸ì„œ ê²€ìƒ‰ â†’ context ë¬¸ìì—´ ìƒì„±
        """
        docs: List[Document] = self.retriever.get_relevant_documents(question)

        if self.debug:
            print("\nğŸ” [RAG ê²€ìƒ‰ ê²°ê³¼] ----------------------")
            for d in docs:
                src = d.metadata.get('source', 'unknown')
                print(f"â€¢ {src}: {d.page_content[:120]}...")
            print("----------------------------------------\n")

        merged = "\n\n".join([d.page_content for d in docs])
        if len(merged) > self.max_context_len:
            merged = merged[: self.max_context_len] + "\n\n...(ë¬¸ë§¥ ê¸¸ì´ ì´ˆê³¼ë¡œ ì¼ë¶€ ìƒëµë¨)"

        # ë¬¸ì„œ ì¶œì²˜ ì¶”ê°€
        if self.include_sources:
            sources = "\n".join(
                [f"- {d.metadata.get('source', 'unknown')}" for d in docs]
            )
            merged += f"\n\n[ì°¸ê³  ë¬¸ì„œ ì¶œì²˜]\n{sources}"

        return merged

    # -----------------------------
    # í¼ë¸”ë¦­ ë©”ì„œë“œ
    # -----------------------------
    def run(self, question: str) -> str:
        """
        ë‹¨ì¼ ì§ˆë¬¸ì— ëŒ€í•´ RAG íŒŒì´í”„ë¼ì¸ ì‹¤í–‰.
        ê²€ìƒ‰ + ìƒì„± ê²°ê³¼ ë¬¸ìì—´ ë°˜í™˜.
        """
        return self.chain.invoke(question)

    def run_with_sources(self, question: str) -> dict:
        """
        ê²€ìƒ‰ëœ ë¬¸ì„œ ì¶œì²˜ê¹Œì§€ í•¨ê»˜ ë°˜í™˜í•˜ëŠ” ë²„ì „.
        """
        docs: List[Document] = self.retriever.get_relevant_documents(question)
        context = "\n\n".join([d.page_content for d in docs])
        answer = self.llm.invoke(
            self.prompt.format(context=context, question=question)
        ).content

        return {
            "answer": answer,
            "sources": [d.metadata.get("source", "unknown") for d in docs],
        }
